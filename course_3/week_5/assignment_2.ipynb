{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prachi/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (19,47) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "loans=pd.read_csv(\"../course_3_data/lending-club-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['grade',              # grade of the loan\n",
    "            'term',               # the term of the loan\n",
    "            'home_ownership',     # home ownership status: own, mortgage or rent\n",
    "            'emp_length',         # number of years of employment\n",
    "           ]\n",
    "loans['safe_loans'] = loans['bad_loans'].apply(lambda x : +1 if x==0 else -1)\n",
    "loans.drop('bad_loans',axis=1,inplace=True)\n",
    "target = 'safe_loans'\n",
    "loans = loans[features + [target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans=pd.get_dummies(loans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx=pd.read_json(\"../course_3_data/module-8-assignment-2-train-idx.json\")\n",
    "test_idx=pd.read_json(\"../course_3_data/module-8-assignment-2-test-idx.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=loans.iloc[train_idx[0]]\n",
    "test_data=loans.iloc[test_idx[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_loans_raw = loans[loans[target] == 1]\n",
    "risky_loans_raw = loans[loans[target] == -1]\n",
    "# Undersample the safe loans.\n",
    "percentage = len(risky_loans_raw)/float(len(safe_loans_raw))\n",
    "risky_loans = risky_loans_raw\n",
    "safe_loans = safe_loans_raw.sample(frac=percentage)\n",
    "loans_data = risky_loans_raw.append(safe_loans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intermediate_node_weighted_mistakes(labels_in_node, data_weights):\n",
    "#     print(labels_in_node,data_weights)\n",
    "    # Sum the weights of all entries with label +1\n",
    "    total_weight_positive = sum(data_weights[labels_in_node == +1])\n",
    "    \n",
    "    # Weight of mistakes for predicting all -1's is equal to the sum above\n",
    "    ### YOUR CODE HERE\n",
    "    weighted_mistakes_all_negative = total_weight_positive\n",
    "    \n",
    "    # Sum the weights of all entries with label -1\n",
    "    ### YOUR CODE HERE\n",
    "    total_weight_negative = sum(data_weights[labels_in_node == -1])\n",
    "    \n",
    "    # Weight of mistakes for predicting all +1's is equal to the sum above\n",
    "    ### YOUR CODE HERE\n",
    "    weighted_mistakes_all_positive = total_weight_negative\n",
    "    \n",
    "    # Return the tuple (weight, class_label) representing the lower of the two weights\n",
    "    #    class_label should be an integer of value +1 or -1.\n",
    "    # If the two weights are identical, return (weighted_mistakes_all_positive,+1)\n",
    "    ### YOUR CODE HERE\n",
    "#     print(weighted_mistakes_all_negative,weighted_mistakes_all_positive)\n",
    "    if weighted_mistakes_all_negative>weighted_mistakes_all_positive:\n",
    "        return (weighted_mistakes_all_positive,+1)\n",
    "    \n",
    "    elif weighted_mistakes_all_negative==weighted_mistakes_all_positive:\n",
    "        return (weighted_mistakes_all_positive,+1)\n",
    "    else:\n",
    "        return (weighted_mistakes_all_negative,-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the data is identical in each feature, this function should return None\n",
    "\n",
    "def best_splitting_feature(data, features, target, data_weights):\n",
    "    \n",
    "    # These variables will keep track of the best feature and the corresponding error\n",
    "    best_feature = None\n",
    "    best_error = float('+inf') \n",
    "    num_points = float(len(data))\n",
    "\n",
    "    # Loop through each feature to consider splitting on that feature\n",
    "    for feature in features:\n",
    "        \n",
    "        # The left split will have all data points where the feature value is 0\n",
    "        # The right split will have all data points where the feature value is 1\n",
    "        left_split = data[data[feature] == 0]\n",
    "        right_split = data[data[feature] == 1]\n",
    "        \n",
    "        # Apply the same filtering to data_weights to create left_data_weights, right_data_weights\n",
    "        ## YOUR CODE HERE\n",
    "        left_data_weights = data_weights[data[feature] == 0]\n",
    "        right_data_weights = data_weights[data[feature] == 1]\n",
    "                    \n",
    "        # DIFFERENT HERE\n",
    "        # Calculate the weight of mistakes for left and right sides\n",
    "        ## YOUR CODE HERE\n",
    "        left_weighted_mistakes, left_class = intermediate_node_weighted_mistakes(left_split[target],left_data_weights)\n",
    "        right_weighted_mistakes, right_class = intermediate_node_weighted_mistakes(right_split[target],right_data_weights)\n",
    "        \n",
    "        # DIFFERENT HERE\n",
    "        # Compute weighted error by computing\n",
    "        #  ( [weight of mistakes (left)] + [weight of mistakes (right)] ) / [total weight of all data points]\n",
    "        ## YOUR CODE HERE\n",
    "        error = (left_weighted_mistakes+right_weighted_mistakes)/len(data_weights)\n",
    "        \n",
    "        # If this is the best error we have found so far, store the feature and the error\n",
    "        if error < best_error:\n",
    "            best_feature = feature\n",
    "            best_error = error\n",
    "    \n",
    "    # Return the best feature we found\n",
    "    return best_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_leaf(target_values, data_weights):\n",
    "    \n",
    "    # Create a leaf node\n",
    "    leaf = {'splitting_feature' : None,\n",
    "            'is_leaf': True}\n",
    "    \n",
    "    # Computed weight of mistakes.\n",
    "    # Store the predicted class (1 or -1) in leaf['prediction']\n",
    "    weighted_error, best_class = intermediate_node_weighted_mistakes(target_values, data_weights)\n",
    "    leaf['prediction'] = best_class ## YOUR CODE HERE\n",
    "    \n",
    "    return leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_decision_tree_create(data, features, target, data_weights, current_depth = 1, max_depth = 10):\n",
    "    remaining_features = features[:] # Make a copy of the features.\n",
    "    target_values = data[target]\n",
    "    print(\"--------------------------------------------------------------------\")\n",
    "    print(\"Subtree, depth = %s (%s data points).\" % (current_depth, len(target_values)))\n",
    "    \n",
    "    # Stopping condition 1. Error is 0.\n",
    "    if intermediate_node_weighted_mistakes(target_values, data_weights)[0] <= 1e-15:\n",
    "        print(\"Stopping condition 1 reached.\"  )              \n",
    "        return create_leaf(target_values, data_weights)\n",
    "    \n",
    "    # Stopping condition 2. No more features.\n",
    "    if remaining_features == []:\n",
    "        print(\"Stopping condition 2 reached.\" )               \n",
    "        return create_leaf(target_values, data_weights)    \n",
    "    \n",
    "    # Additional stopping condition (limit tree depth)\n",
    "    if current_depth > max_depth:\n",
    "        print(\"Reached maximum depth. Stopping for now.\")\n",
    "        return create_leaf(target_values, data_weights)\n",
    "    \n",
    "    # If all the datapoints are the same, splitting_feature will be None. Create a leaf\n",
    "    splitting_feature = best_splitting_feature(data, features, target, data_weights)\n",
    "    remaining_features.remove(splitting_feature)\n",
    "        \n",
    "    left_split = data[data[splitting_feature] == 0]\n",
    "    right_split = data[data[splitting_feature] == 1]\n",
    "    \n",
    "    left_data_weights = data_weights[data[splitting_feature] == 0]\n",
    "    right_data_weights = data_weights[data[splitting_feature] == 1]\n",
    "    \n",
    "    print(\"Split on feature %s. (%s, %s)\" % (\\\n",
    "              splitting_feature, len(left_split), len(right_split)))\n",
    "    \n",
    "    # Create a leaf node if the split is \"perfect\"\n",
    "    if len(left_split) == len(data):\n",
    "        print(\"Creating leaf node.\")\n",
    "        return create_leaf(left_split[target], data_weights)\n",
    "    if len(right_split) == len(data):\n",
    "        print(\"Creating leaf node.\")\n",
    "        return create_leaf(right_split[target], data_weights)\n",
    "    \n",
    "    # Repeat (recurse) on left and right subtrees\n",
    "    left_tree = weighted_decision_tree_create(\n",
    "        left_split, remaining_features, target, left_data_weights, current_depth + 1, max_depth)\n",
    "    right_tree = weighted_decision_tree_create(\n",
    "        right_split, remaining_features, target, right_data_weights, current_depth + 1, max_depth)\n",
    "    \n",
    "    return {'is_leaf'          : False, \n",
    "            'prediction'       : None,\n",
    "            'splitting_feature': splitting_feature,\n",
    "            'left'             : left_tree, \n",
    "            'right'            : right_tree}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_nodes(tree):\n",
    "    if tree['is_leaf']:\n",
    "        return 1\n",
    "    return 1 + count_nodes(tree['left']) + count_nodes(tree['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(tree, x, annotate = False):   \n",
    "    # If the node is a leaf node.\n",
    "    if tree['is_leaf']:\n",
    "        if annotate: \n",
    "            print(\"At leaf, predicting %s\" % tree['prediction'])\n",
    "        return tree['prediction'] \n",
    "    else:\n",
    "        # Split on feature.\n",
    "        split_feature_value = x[tree['splitting_feature']]\n",
    "        if annotate: \n",
    "            print(\"Split on %s = %s\" % (tree['splitting_feature'], split_feature_value))\n",
    "        if split_feature_value == 0:\n",
    "            return classify(tree['left'], x, annotate)\n",
    "        else:\n",
    "            return classify(tree['right'], x, annotate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification_error(tree, data):\n",
    "    # Apply the classify(tree, x) to each row in your data\n",
    "    prediction=[]\n",
    "    for i in range(len(data)):\n",
    "        prediction.append(classify(tree,data.iloc[i]))\n",
    "        \n",
    "    # Once you've made the predictions, calculate the classification error\n",
    "    return (prediction != data[target]).sum() / float(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>safe_loans</th>\n",
       "      <th>grade_A</th>\n",
       "      <th>grade_B</th>\n",
       "      <th>grade_C</th>\n",
       "      <th>grade_D</th>\n",
       "      <th>grade_E</th>\n",
       "      <th>grade_F</th>\n",
       "      <th>grade_G</th>\n",
       "      <th>term_ 36 months</th>\n",
       "      <th>term_ 60 months</th>\n",
       "      <th>...</th>\n",
       "      <th>emp_length_10+ years</th>\n",
       "      <th>emp_length_2 years</th>\n",
       "      <th>emp_length_3 years</th>\n",
       "      <th>emp_length_4 years</th>\n",
       "      <th>emp_length_5 years</th>\n",
       "      <th>emp_length_6 years</th>\n",
       "      <th>emp_length_7 years</th>\n",
       "      <th>emp_length_8 years</th>\n",
       "      <th>emp_length_9 years</th>\n",
       "      <th>emp_length_&lt; 1 year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122572</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122575</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122588</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122599</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122603</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37224 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        safe_loans  grade_A  grade_B  grade_C  grade_D  grade_E  grade_F  \\\n",
       "1               -1        0        0        1        0        0        0   \n",
       "6               -1        0        0        0        0        0        1   \n",
       "7               -1        0        1        0        0        0        0   \n",
       "10              -1        0        0        1        0        0        0   \n",
       "12              -1        0        1        0        0        0        0   \n",
       "...            ...      ...      ...      ...      ...      ...      ...   \n",
       "122572           1        0        1        0        0        0        0   \n",
       "122575           1        0        0        1        0        0        0   \n",
       "122588           1        1        0        0        0        0        0   \n",
       "122599           1        0        0        0        0        0        0   \n",
       "122603           1        0        0        0        1        0        0   \n",
       "\n",
       "        grade_G  term_ 36 months  term_ 60 months  ...  emp_length_10+ years  \\\n",
       "1             0                0                1  ...                     0   \n",
       "6             0                0                1  ...                     0   \n",
       "7             0                0                1  ...                     0   \n",
       "10            0                1                0  ...                     0   \n",
       "12            0                1                0  ...                     0   \n",
       "...         ...              ...              ...  ...                   ...   \n",
       "122572        0                1                0  ...                     0   \n",
       "122575        0                1                0  ...                     0   \n",
       "122588        0                1                0  ...                     0   \n",
       "122599        1                0                1  ...                     1   \n",
       "122603        0                1                0  ...                     1   \n",
       "\n",
       "        emp_length_2 years  emp_length_3 years  emp_length_4 years  \\\n",
       "1                        0                   0                   0   \n",
       "6                        0                   0                   1   \n",
       "7                        0                   0                   0   \n",
       "10                       0                   0                   0   \n",
       "12                       0                   1                   0   \n",
       "...                    ...                 ...                 ...   \n",
       "122572                   0                   0                   0   \n",
       "122575                   0                   0                   0   \n",
       "122588                   0                   1                   0   \n",
       "122599                   0                   0                   0   \n",
       "122603                   0                   0                   0   \n",
       "\n",
       "        emp_length_5 years  emp_length_6 years  emp_length_7 years  \\\n",
       "1                        0                   0                   0   \n",
       "6                        0                   0                   0   \n",
       "7                        0                   0                   0   \n",
       "10                       0                   0                   0   \n",
       "12                       0                   0                   0   \n",
       "...                    ...                 ...                 ...   \n",
       "122572                   0                   0                   0   \n",
       "122575                   1                   0                   0   \n",
       "122588                   0                   0                   0   \n",
       "122599                   0                   0                   0   \n",
       "122603                   0                   0                   0   \n",
       "\n",
       "        emp_length_8 years  emp_length_9 years  emp_length_< 1 year  \n",
       "1                        0                   0                    1  \n",
       "6                        0                   0                    0  \n",
       "7                        0                   0                    1  \n",
       "10                       0                   0                    1  \n",
       "12                       0                   0                    0  \n",
       "...                    ...                 ...                  ...  \n",
       "122572                   0                   0                    1  \n",
       "122575                   0                   0                    0  \n",
       "122588                   0                   0                    0  \n",
       "122599                   0                   0                    0  \n",
       "122603                   0                   0                    0  \n",
       "\n",
       "[37224 rows x 25 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=list(train_data.columns[1:])\n",
    "train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature home_ownership_RENT. (20514, 16710)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (20514 data points).\n",
      "Split on feature grade_F. (19613, 901)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (19613 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (901 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (16710 data points).\n",
      "Split on feature grade_D. (13315, 3395)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (13315 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (3395 data points).\n",
      "Stopping condition 1 reached.\n"
     ]
    }
   ],
   "source": [
    "# Assign weights\n",
    "example_data_weights = np.array([1.] * 10 + [0.]*(len(train_data) - 20) + [1.] * 10)\n",
    "# Train a weighted decision tree model.\n",
    "small_data_decision_tree_subset_20 = weighted_decision_tree_create(train_data, features, target,\n",
    "                         example_data_weights, max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48124865678057166"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_classification_error(small_data_decision_tree_subset_20, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "from math import exp\n",
    "\n",
    "def adaboost_with_tree_stumps(data, features, target, num_tree_stumps):\n",
    "    # start with unweighted data\n",
    "    alpha = np.array([1.]*len(data))\n",
    "    weights = []\n",
    "    tree_stumps = []\n",
    "    target_values = data[target]\n",
    "    \n",
    "    for t in range(num_tree_stumps):\n",
    "#         print(alpha)\n",
    "        print('=====================================================')\n",
    "        print('Adaboost Iteration %d' % t)\n",
    "        print('=====================================================')        \n",
    "        # Learn a weighted decision tree stump. Use max_depth=1\n",
    "        tree_stump = weighted_decision_tree_create(data, features, target, data_weights=alpha, max_depth=1)\n",
    "        tree_stumps.append(tree_stump)\n",
    "        print(tree_stump)\n",
    "        # Make predictions\n",
    "        predictions=[]\n",
    "        for i in range(len(data)):\n",
    "            predictions.append(classify(tree_stump,data.iloc[i]))\n",
    "\n",
    "        # Produce a Boolean array indicating whether\n",
    "        # each data point was correctly classified\n",
    "        is_correct = predictions == target_values\n",
    "        is_wrong   = predictions != target_values\n",
    "        \n",
    "        # Compute weighted error\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        \n",
    "        weighted_error = np.sum(alpha[is_wrong])/np.sum(alpha)\n",
    "#         weighted_error=weighted_error[0]/sum(alpha)\n",
    "        # Compute model coefficient using weighted error\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        er=(1-weighted_error)/weighted_error\n",
    "        \n",
    "        weight = 0.5*log(er)\n",
    "        weights.append(weight)\n",
    "        \n",
    "        # Adjust weights on data point\n",
    "        adjustment = is_correct.apply(lambda is_correct : exp(-weight) if is_correct else exp(weight))\n",
    "        \n",
    "        # Scale alpha by multiplying by adjustment\n",
    "        # Then normalize data points weights\n",
    "        ## YOUR CODE HERE \n",
    "        alpha=alpha*adjustment\n",
    "    \n",
    "    return weights, tree_stumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "Adaboost Iteration 0\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature term_ 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9223 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (28001 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'term_ 36 months', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 1\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_A. (32094, 5130)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32094 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5130 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_A', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 2\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_D. (30465, 6759)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (30465 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (6759 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_D', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 3\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature home_ownership_MORTGAGE. (19846, 17378)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (19846 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (17378 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'home_ownership_MORTGAGE', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 4\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_B. (26858, 10366)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (26858 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (10366 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_B', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 5\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_E. (33815, 3409)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (33815 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3409 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_E', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 6\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_A. (32094, 5130)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32094 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5130 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_A', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 7\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_F. (35512, 1712)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35512 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1712 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_F', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 8\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_A. (32094, 5130)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32094 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5130 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_A', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 9\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_F. (35512, 1712)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35512 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1712 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_F', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}}\n"
     ]
    }
   ],
   "source": [
    "stump_weights,tree_stumps=adaboost_with_tree_stumps(train_data,features,target,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.15802933659263743,\n",
       " 0.1768236329363596,\n",
       " 0.0931188897118565,\n",
       " 0.07288885525865706,\n",
       " 0.06706306914162646,\n",
       " 0.0645691696162263,\n",
       " 0.05456055779184845,\n",
       " 0.0435109367337119,\n",
       " 0.028988711500360906,\n",
       " 0.019333438170587768]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stump_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_adaboost(stump_weights, tree_stumps, data):\n",
    "    scores = np.array([0.]*len(data))\n",
    "    \n",
    "    for i, tree_stump in enumerate(tree_stumps):\n",
    "        predictions=[]\n",
    "        for j in range(len(data)):\n",
    "            predictions.append(classify(tree_stump,data.iloc[j]))\n",
    "\n",
    "        # Accumulate predictions on scores array\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "        scores=scores+np.dot(predictions,stump_weights[i])\n",
    "    \n",
    "         \n",
    "    return list(map(lambda x:+1 if x>0 else -1,scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " ...]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_adaboost(stump_weights,tree_stumps,train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "Adaboost Iteration 0\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature term_ 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9223 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (28001 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'term_ 36 months', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 1\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_A. (32094, 5130)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32094 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5130 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_A', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 2\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_D. (30465, 6759)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (30465 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (6759 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_D', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 3\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature home_ownership_MORTGAGE. (19846, 17378)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (19846 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (17378 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'home_ownership_MORTGAGE', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 4\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_B. (26858, 10366)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (26858 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (10366 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_B', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 5\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_E. (33815, 3409)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (33815 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3409 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_E', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 6\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_A. (32094, 5130)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32094 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5130 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_A', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 7\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_F. (35512, 1712)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35512 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1712 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_F', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 8\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_A. (32094, 5130)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32094 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5130 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_A', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 9\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_F. (35512, 1712)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35512 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1712 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_F', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 10\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_D. (30465, 6759)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (30465 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (6759 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_D', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "Adaboost Iteration 11\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_B. (26858, 10366)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (26858 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (10366 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_B', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 12\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_F. (35512, 1712)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35512 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1712 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_F', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 13\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature term_ 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9223 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (28001 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'term_ 36 months', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 14\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_E. (33815, 3409)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (33815 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3409 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_E', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 15\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature emp_length_4 years. (34593, 2631)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (34593 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (2631 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'emp_length_4 years', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 16\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_F. (35512, 1712)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35512 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1712 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_F', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 17\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature emp_length_2 years. (33652, 3572)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (33652 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3572 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'emp_length_2 years', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 18\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_E. (33815, 3409)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (33815 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3409 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_E', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 19\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature emp_length_10+ years. (26901, 10323)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (26901 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (10323 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'emp_length_10+ years', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 20\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_A. (32094, 5130)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32094 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5130 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_A', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 21\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on feature grade_G. (36788, 436)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (36788 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (436 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_G', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 22\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature emp_length_3 years. (34099, 3125)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (34099 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3125 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'emp_length_3 years', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 23\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_F. (35512, 1712)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35512 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1712 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_F', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 24\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature home_ownership_OWN. (34149, 3075)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (34149 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3075 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'home_ownership_OWN', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 25\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_G. (36788, 436)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (36788 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (436 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_G', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 26\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature emp_length_4 years. (34593, 2631)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (34593 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (2631 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'emp_length_4 years', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 27\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_G. (36788, 436)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (36788 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (436 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_G', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 28\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature term_ 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9223 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (28001 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'term_ 36 months', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 29\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_C. (27812, 9412)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (27812 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9412 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_C', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n"
     ]
    }
   ],
   "source": [
    "stump_weights,tree_stumps=adaboost_with_tree_stumps(train_data,features,target,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, training error = 0.4216365785514722\n",
      "Iteration 2, training error = 0.43343004513217276\n",
      "Iteration 3, training error = 0.4000376101439931\n",
      "Iteration 4, training error = 0.4000376101439931\n",
      "Iteration 5, training error = 0.3847249086610789\n",
      "Iteration 6, training error = 0.3846174511068128\n",
      "Iteration 7, training error = 0.3827638082957232\n",
      "Iteration 8, training error = 0.3846174511068128\n",
      "Iteration 9, training error = 0.3827638082957232\n",
      "Iteration 10, training error = 0.38144745325596385\n",
      "Iteration 11, training error = 0.38144745325596385\n",
      "Iteration 12, training error = 0.38144745325596385\n",
      "Iteration 13, training error = 0.38144745325596385\n",
      "Iteration 14, training error = 0.38144745325596385\n",
      "Iteration 15, training error = 0.38144745325596385\n",
      "Iteration 16, training error = 0.3814205888673974\n",
      "Iteration 17, training error = 0.3814205888673974\n",
      "Iteration 18, training error = 0.3816355039759295\n",
      "Iteration 19, training error = 0.3816355039759295\n",
      "Iteration 20, training error = 0.3816355039759295\n",
      "Iteration 21, training error = 0.3814205888673974\n",
      "Iteration 22, training error = 0.382441435632925\n",
      "Iteration 23, training error = 0.3814205888673974\n",
      "Iteration 24, training error = 0.3824145712443585\n",
      "Iteration 25, training error = 0.3814205888673974\n",
      "Iteration 26, training error = 0.3824145712443585\n",
      "Iteration 27, training error = 0.3813668600902643\n",
      "Iteration 28, training error = 0.38155491081022996\n",
      "Iteration 29, training error = 0.3818772834730282\n",
      "Iteration 30, training error = 0.38182355469589513\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "error_all = []\n",
    "for n in range(1, 31):\n",
    "    predictions = predict_adaboost(stump_weights[:n], tree_stumps[:n], train_data)\n",
    "    error = 1.0 - accuracy_score(train_data[target], predictions)\n",
    "    error_all.append(error)\n",
    "    print (\"Iteration %s, training error = %s\" % (n, error_all[n-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = 7, 5\n",
    "plt.plot(range(1,31), error_all, '-', linewidth=4.0, label='Training error')\n",
    "plt.title('Performance of Adaboost ensemble')\n",
    "plt.xlabel('# of iterations')\n",
    "plt.ylabel('Classification error')\n",
    "plt.legend(loc='best', prop={'size':15})\n",
    "\n",
    "plt.rcParams.update({'font.size': 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "Adaboost Iteration 0\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9284 data points).\n",
      "Split on feature term_ 36 months. (2322, 6962)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (2322 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (6962 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'term_ 36 months', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 1\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9284 data points).\n",
      "Split on feature grade_A. (7992, 1292)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (7992 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1292 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_A', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 2\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9284 data points).\n",
      "Split on feature grade_D. (7564, 1720)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (7564 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1720 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_D', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 3\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9284 data points).\n",
      "Split on feature grade_B. (6786, 2498)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (6786 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (2498 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_B', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 4\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9284 data points).\n",
      "Split on feature home_ownership_RENT. (5075, 4209)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5075 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (4209 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'home_ownership_RENT', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 5\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9284 data points).\n",
      "Split on feature grade_F. (8874, 410)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (8874 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (410 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_F', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 6\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9284 data points).\n",
      "Split on feature grade_A. (7992, 1292)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (7992 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1292 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_A', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 7\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9284 data points).\n",
      "Split on feature grade_E. (8383, 901)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (8383 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (901 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_E', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 8\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9284 data points).\n",
      "Split on feature emp_length_2 years. (8398, 886)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (8398 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (886 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'emp_length_2 years', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 9\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9284 data points).\n",
      "Split on feature grade_F. (8874, 410)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (8874 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (410 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_F', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 10\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9284 data points).\n",
      "Split on feature emp_length_3 years. (8513, 771)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (8513 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (771 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'emp_length_3 years', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "Adaboost Iteration 11\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9284 data points).\n",
      "Split on feature grade_F. (8874, 410)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (8874 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (410 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_F', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 12\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9284 data points).\n",
      "Split on feature emp_length_10+ years. (6770, 2514)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (6770 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (2514 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'emp_length_10+ years', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 13\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9284 data points).\n",
      "Split on feature grade_D. (7564, 1720)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (7564 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1720 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_D', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 14\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9284 data points).\n",
      "Split on feature grade_F. (8874, 410)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (8874 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (410 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_F', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 15\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9284 data points).\n",
      "Split on feature grade_A. (7992, 1292)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (7992 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1292 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_A', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 16\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9284 data points).\n",
      "Split on feature grade_E. (8383, 901)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (8383 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (901 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_E', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 17\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9284 data points).\n",
      "Split on feature grade_B. (6786, 2498)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (6786 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (2498 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_B', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 18\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9284 data points).\n",
      "Split on feature home_ownership_OWN. (8523, 761)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (8523 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (761 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'home_ownership_OWN', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 19\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9284 data points).\n",
      "Split on feature emp_length_2 years. (8398, 886)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (8398 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (886 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'emp_length_2 years', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 20\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9284 data points).\n",
      "Split on feature emp_length_6 years. (8687, 597)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (8687 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (597 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'emp_length_6 years', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 21\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9284 data points).\n",
      "Split on feature term_ 36 months. (2322, 6962)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (2322 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (6962 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'term_ 36 months', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "Adaboost Iteration 22\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9284 data points).\n",
      "Split on feature grade_F. (8874, 410)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (8874 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (410 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_F', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 23\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9284 data points).\n",
      "Split on feature emp_length_< 1 year. (8447, 837)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (8447 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (837 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'emp_length_< 1 year', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 24\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9284 data points).\n",
      "Split on feature grade_G. (9160, 124)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9160 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (124 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_G', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 25\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9284 data points).\n",
      "Split on feature grade_A. (7992, 1292)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (7992 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1292 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_A', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 26\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9284 data points).\n",
      "Split on feature grade_G. (9160, 124)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9160 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (124 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_G', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 27\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9284 data points).\n",
      "Split on feature grade_D. (7564, 1720)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (7564 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1720 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_D', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 28\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9284 data points).\n",
      "Split on feature grade_C. (6945, 2339)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (6945 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (2339 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_C', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}\n",
      "=====================================================\n",
      "Adaboost Iteration 29\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9284 data points).\n",
      "Split on feature grade_G. (9160, 124)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9160 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (124 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "{'is_leaf': False, 'prediction': None, 'splitting_feature': 'grade_G', 'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}, 'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}}\n"
     ]
    }
   ],
   "source": [
    "stump_weights_test,tree_stumps_test=adaboost_with_tree_stumps(test_data,features,target,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, test error = 0.4233089185695821\n",
      "Iteration 2, test error = 0.4284791038345541\n",
      "Iteration 3, test error = 0.3981042654028436\n",
      "Iteration 4, test error = 0.3981042654028436\n",
      "Iteration 5, test error = 0.37990090478242133\n",
      "Iteration 6, test error = 0.38000861697544164\n",
      "Iteration 7, test error = 0.37925463162429984\n",
      "Iteration 8, test error = 0.38000861697544164\n",
      "Iteration 9, test error = 0.37925463162429984\n",
      "Iteration 10, test error = 0.37796208530805686\n",
      "Iteration 11, test error = 0.37796208530805686\n",
      "Iteration 12, test error = 0.37796208530805686\n",
      "Iteration 13, test error = 0.37796208530805686\n",
      "Iteration 14, test error = 0.37796208530805686\n",
      "Iteration 15, test error = 0.37796208530805686\n",
      "Iteration 16, test error = 0.37817750969409736\n",
      "Iteration 17, test error = 0.37817750969409736\n",
      "Iteration 18, test error = 0.37785437311503667\n",
      "Iteration 19, test error = 0.37785437311503667\n",
      "Iteration 20, test error = 0.37785437311503667\n",
      "Iteration 21, test error = 0.37817750969409736\n",
      "Iteration 22, test error = 0.37731581214993537\n",
      "Iteration 23, test error = 0.37817750969409736\n",
      "Iteration 24, test error = 0.3772080999569152\n",
      "Iteration 25, test error = 0.37817750969409736\n",
      "Iteration 26, test error = 0.3772080999569152\n",
      "Iteration 27, test error = 0.37860835846617835\n",
      "Iteration 28, test error = 0.37817750969409736\n",
      "Iteration 29, test error = 0.37699267557087457\n",
      "Iteration 30, test error = 0.3774235243429557\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "test_error_all = []\n",
    "for n in range(1, 31):\n",
    "    predictions = predict_adaboost(stump_weights[:n], tree_stumps[:n], test_data)\n",
    "    error = 1.0 - accuracy_score(test_data[target], predictions)\n",
    "    test_error_all.append(error)\n",
    "    print (\"Iteration %s, test error = %s\" % (n, test_error_all[n-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = 7, 5\n",
    "plt.plot(range(1,31), error_all, '-', linewidth=4.0, label='Training error')\n",
    "plt.plot(range(1,31), test_error_all, '-', linewidth=4.0, label='Test error')\n",
    "\n",
    "plt.title('Performance of Adaboost ensemble')\n",
    "plt.xlabel('# of iterations')\n",
    "plt.ylabel('Classification error')\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.legend(loc='best', prop={'size':15})\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
